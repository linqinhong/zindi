{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification,RobertaForSequenceClassification,RobertaModel,AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"/data/linqinhong/zindi/vaccine/data/Train.csv\")\n",
    "test_df=pd.read_csv(\"/data/linqinhong/zindi/vaccine/data/Test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "na_list=list(train_df[train_df[\"label\"].isnull()==True].index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.drop(na_list,axis=0,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[train_df[\"label\"].isnull()==True]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.drop(\"tweet_id\",inplace=True,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.drop(\"tweet_id\",inplace=True,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(lambda x:x.replace(\"&amp\",\"\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(lambda x:str(x).replace(\"&amp\",\"\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除带有#的，不一定能提高表现，需要对比"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "pattern1=re.compile(r\"#[\\w]*\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(lambda x:re.sub(pattern1,\"\",x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(lambda x:re.sub(pattern1,\"\",x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除带有<>符号里的内容"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pattern2=re.compile(r\"<[\\w]*>\")\n",
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(lambda x:re.sub(pattern2,\"\",x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(lambda x:re.sub(pattern2,\"\",x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(str.lower)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(str.lower)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword=stopwords.words(\"english\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import contractions\n",
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(contractions.fix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(contractions.fix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    return \" \".join(i for i in text.split() if i not in stopword)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"safe_text\"]=train_df[\"safe_text\"].apply(remove_stopword)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"safe_text\"]=test_df[\"safe_text\"].apply(remove_stopword)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"label\"]=train_df[\"label\"].apply(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelname='bert-base-uncased'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(modelname)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model=AutoModel.from_pretrained(modelname)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset=Dataset.from_pandas(train_df)\n",
    "test_dataset=Dataset.from_pandas(test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset=Dataset.from_pandas(test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    result=tokenizer(text[\"safe_text\"])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.map(tokenize,batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset=test_dataset.map(tokenize,batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset[\"input_ids\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.remove_columns(\"safe_text\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset=test_dataset.remove_columns(\"safe_text\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset.column_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.rename_column(\"label\",\"labels\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_labels(text):\n",
    "    return {\"labels\":text[\"labels\"]+1}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.map(process_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.remove_columns(\"agreement\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "num_split=5\n",
    "seed=3407\n",
    "#SKF=StratifiedKFold(n_splits=num_split,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device(\"cuda:1\") if torch.cuda.is_available()==True else torch.device(\"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "datacollator=DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import Linear,ReLU,CrossEntropyLoss\n",
    "from torch import softmax,sigmoid\n",
    "\"\"\"linear1=Linear(1024,1024,bias=True).to(device)\n",
    "linear2=Linear(1024,3,bias=True).to(device)\n",
    "loss_fn=CrossEntropyLoss()\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"def classifier(input,labels):\n",
    "    output=linear2(linear1(input))\n",
    "    output=softmax(sigmoid(output),dim=0)\n",
    "    return output\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self,input_channels,hidden,output_channels):\n",
    "        super(classifier,self).__init__()\n",
    "        self.linear1=nn.Linear(input_channels,hidden)\n",
    "        self.linear2=nn.Linear(hidden,output_channels)\n",
    "        self.batchnorm=nn.BatchNorm1d(input_channels,eps=1e-5,)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x=self.dropout(x)\n",
    "        hidden=self.linear1(x)\n",
    "        hidden=self.batchnorm(hidden)\n",
    "        active=self.relu(hidden)\n",
    "        #可以添加一个残差连接https://www.kaggle.com/code/prashantkikani/nfl-starter-mlp-feature-engg\n",
    "        active=self.dropout(active)\n",
    "        output=self.linear2(active)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Classifier=classifier(768,768,3).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "lr_rate=0.0005\n",
    "optimizer=AdamW(Classifier.parameters(),lr=lr_rate)\n",
    "#lr_scheduler=get_scheduler('linear',optimizer=optimizer,num_warmup_steps=20,num_training_steps=train_steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import evaluate\n",
    "import math\n",
    "from torch import softmax\n",
    "metric_train=evaluate.load(\"accuracy\")\n",
    "metric_val=evaluate.load(\"accuracy\")\n",
    "epoches=100\n",
    "total_loss=[]\n",
    "from tqdm.auto import tqdm\n",
    "epoch_bar=tqdm(range(epoches))\n",
    "loss_fn=CrossEntropyLoss()\n",
    "model.eval()\n",
    "for epoch in range(epoches):\n",
    "    lr_rate=0.0005/(epoch/20+1)\n",
    "    optimizer=AdamW(Classifier.parameters(),lr=lr_rate)\n",
    "    KF = KFold(n_splits=num_split, shuffle=True,random_state=seed+epoch)\n",
    "    split_result=KF.split(train_dataset,train_dataset[\"labels\"])\n",
    "    for train_split,val_split in split_result:\n",
    "        train_split_data=train_dataset.select(train_split)#.remove_columns(\"labels\")\n",
    "        #train_split_label=train_dataset.select(train_split)[\"labels\"]\n",
    "        val_split_data=train_dataset.select(val_split)#.remove_columns(\"labels\")\n",
    "        #val_split_labels=\n",
    "        train_dataloader=DataLoader(train_split_data,shuffle=True,batch_size=64,collate_fn=datacollator)\n",
    "        val_dataloader=DataLoader(val_split_data,shuffle=True,batch_size=16,collate_fn=datacollator)\n",
    "        train_steps=len(train_dataloader)\n",
    "        lr_scheduler=get_scheduler('linear',optimizer=optimizer,num_warmup_steps=0.2*train_steps,num_training_steps=train_steps)\n",
    "        #train_bar=tqdm(range(len(train_dataloader)))\n",
    "        #val_bar=tqdm(range(len(val_dataloader)))\n",
    "        Loss=0\n",
    "        for batch in train_dataloader:\n",
    "            Classifier.train()\n",
    "            batch={k:v.to(device) for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output=model(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"])\n",
    "            labels=batch[\"labels\"]\n",
    "            class_output=Classifier(output.pooler_output)\n",
    "            loss=loss_fn(class_output,labels)\n",
    "            Loss+=loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            train_pred=torch.argmax(class_output,dim=1)\n",
    "            metric_train.add_batch(predictions=train_pred,references=batch[\"labels\"])\n",
    "            train_acc=metric_train.compute()\n",
    "            #train_bar.update(1)\n",
    "        print(train_acc)\n",
    "        print(Loss/len(train_dataloader))\n",
    "        total_loss.append(Loss/len(train_dataloader))\n",
    "            #break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_split_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "torch.save(Classifier.state_dict(),\"/data/linqinhong/zindi/vaccine/data/MLP_bert1.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_dict=torch.load(\"/data/linqinhong/zindi/vaccine/data/MLP_bert1.pt\")\n",
    "Classifier.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "Classifier.eval()\n",
    "result=[]\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=64,shuffle=True,collate_fn=datacollator)\n",
    "for batch_test in test_dataloader:\n",
    "    batch_test={k:v.to(device) for k,v in batch_test.items()}\n",
    "    testoutput=model(**batch_test)\n",
    "    logits=Classifier(testoutput.pooler_output)\n",
    "    result.extend([(i-1)*j for i,j in zip(torch.argmax(logits,dim=1).cpu().tolist(),torch.max(softmax(logits,dim=1),dim=1).values.tolist())])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "5177"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "raw_test=pd.read_csv(\"/data/linqinhong/zindi/vaccine/data/Test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "raw_test[\"target\"]=result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "      tweet_id    target\n0     00BHHHP1  0.997660\n1     00UNMD0E  0.999457\n2     01AXPTJF  0.678370\n3     01HOEQJW -0.829689\n4     01JUKMAO  0.000000\n...        ...       ...\n5172  ZXVVNC5O  0.000000\n5173  ZYIANVI8  0.000000\n5174  ZYITEHAH  0.000000\n5175  ZZ3BMBTG  0.690118\n5176  ZZIYCVNH  0.000000\n\n[5177 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00BHHHP1</td>\n      <td>0.997660</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00UNMD0E</td>\n      <td>0.999457</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01AXPTJF</td>\n      <td>0.678370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01HOEQJW</td>\n      <td>-0.829689</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01JUKMAO</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5172</th>\n      <td>ZXVVNC5O</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5173</th>\n      <td>ZYIANVI8</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5174</th>\n      <td>ZYITEHAH</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5175</th>\n      <td>ZZ3BMBTG</td>\n      <td>0.690118</td>\n    </tr>\n    <tr>\n      <th>5176</th>\n      <td>ZZIYCVNH</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5177 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "raw_test.drop(\"safe_text\",axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "raw_test.to_csv(\"/data/linqinhong/zindi/vaccine/data/result.csv\",index=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
